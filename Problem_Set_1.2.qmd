---
title: "Problem Set 1"
author: "Charlie Jordan"
format:
  html:
    self-contained: true
    embed-resources: true 
    code-fold: true
    fig-format: png
execute:
  echo: true
  warning: false
  message: false
---

```{r setup}

# Files

abalone_data_path <- "https://raw.githubusercontent.com/charlieejordan/Stats_506_Fall_2025/main/abalone.data"
food_path         <- "https://raw.githubusercontent.com/charlieejordan/Stats_506_Fall_2025/main/food_expenditure.csv"

clean_names_base <- function(nms) {
  nms <- gsub("[^A-Za-z0-9]+", "_", nms)
  nms <- gsub("^_+|_+$", "", nms)
  nms <- tolower(nms)
  nms[nms == ""] <- paste0("x", seq_len(sum(nms == "")))
  make.unique(nms, sep = "_")
}

safe_cor <- function(x, y) {
  x <- suppressWarnings(as.numeric(x))
  y <- suppressWarnings(as.numeric(y))
  if (!length(x) || !length(y)) return(NA_real_)
  if (all(!is.finite(x)) || all(!is.finite(y))) return(NA_real_)
  suppressWarnings(stats::cor(x, y, use = "complete.obs"))
}

guess_col <- function(nms, patterns) {
  for (p in patterns) {
    hits <- grep(p, nms, ignore.case = TRUE, value = TRUE)
    if (length(hits) > 0) return(hits[1])
  }
  NA_character_
}

guess_numeric_cols <- function(df, patterns, k = 4, exclude = character(0)) {
  nms <- names(df)
  cand <- unique(unlist(lapply(patterns, function(p) grep(p, nms, ignore.case = TRUE, value = TRUE))))
  cand <- setdiff(cand, exclude)
  cand <- cand[vapply(df[cand], is.numeric, TRUE)]
  if (length(cand) >= k) return(cand[1:k])
  nums <- nms[vapply(df, is.numeric, TRUE)]
  nums <- setdiff(nums, exclude)
  if (!length(nums)) return(character(0))
  vrs <- sapply(df[nums], function(x) var(x, na.rm = TRUE))
  nums[order(vrs, decreasing = TRUE)][1:min(k, length(nums))]
}
```

# Problem 1 — Abalone Data

```{r}
abalone <- read.csv(abalone_data_path, header = FALSE, stringsAsFactors = FALSE)
names(abalone) <- c(
  "sex","length","diameter","height",
  "whole_weight","shucked_weight","viscera_weight","shell_weight","rings"
)
num_cols <- setdiff(names(abalone), "sex")
for (nm in num_cols) abalone[[nm]] <- suppressWarnings(as.numeric(abalone[[nm]]))
head(abalone, 5)

```

## Observations by sex

```{r}
as.data.frame(table(abalone$sex))
```

## Which weight has the highest correlation with rings?

```{r}
weight_vars <- c("whole_weight","shucked_weight","viscera_weight","shell_weight")

corr_overall <- data.frame(
  weight = weight_vars,
  correlation = sapply(weight_vars, function(v) safe_cor(abalone[[v]], abalone$rings)),
  stringsAsFactors = FALSE
)
corr_overall <- corr_overall[order(-corr_overall$correlation), ]
corr_overall

```

**Answer:** The top row is the most correlated weight with rings.

## For that weight, which sex has the highest correlation with rings?

```{r}
top_weight <- corr_overall$weight[which.max(corr_overall$correlation)]
sp <- split(abalone, abalone$sex)
data.frame(
  sex = names(sp),
  correlation = sapply(sp, function(df) safe_cor(df[[top_weight]], df$rings))
)
```

**Answer:** The first row above shows the sex with the highest correlation for top weight.

## What are the weights of the abalone with the most rings?

```{r}
cols_to_show <- c("sex", weight_vars, "rings")
abalone[abalone$rings == max(abalone$rings, na.rm = TRUE), cols_to_show]

```

## What percentage of abalones have viscera weight \> shell weight?

```{r}
round(mean(abalone$viscera_weight > abalone$shell_weight, na.rm = TRUE) * 100, 2)

```

## Correlations between weights and rings, by sex

```{r}
do.call(rbind, lapply(split(abalone, abalone$sex), function(df) {
  data.frame(
    sex = unique(df$sex),
    whole_weight   = safe_cor(df$whole_weight,   df$rings),
    shucked_weight = safe_cor(df$shucked_weight, df$rings),
    viscera_weight = safe_cor(df$viscera_weight, df$rings),
    shell_weight   = safe_cor(df$shell_weight,   df$rings)
  )
}))
```

## Table: correlations between weights and rings, within each sex

```{r}
do.call(rbind, lapply(split(abalone, abalone$sex), function(df) {
  data.frame(
    sex = unique(df$sex),
    whole_weight   = safe_cor(df$whole_weight,   df$rings),
    shucked_weight = safe_cor(df$shucked_weight, df$rings),
    viscera_weight = safe_cor(df$viscera_weight, df$rings),
    shell_weight   = safe_cor(df$shell_weight,   df$rings)
  )
}))

```

## T-tests: do mean rings differ across sexes?

```{r}
# ---- Robust t-tests + interpretation for Problem 1 ----
# Works whether your columns are 'Sex'/'Rings' or 'sex'/'rings', etc.

# 1) Make a standardized copy of abalone with lower_snake_case names
ab <- abalone
std_names <- function(x){
  x <- tolower(x)
  x <- gsub("[^a-z0-9]+", "_", x)
  x <- gsub("^_|_$", "", x)
  gsub("_+", "_", x)
}
names(ab) <- std_names(names(ab))

# 2) Verify required columns exist (sex, rings)
req <- c("sex","rings")
missing <- setdiff(req, names(ab))
if (length(missing) > 0) {
  stop(sprintf("Required columns not found after standardization: %s\nHave: %s",
               paste(missing, collapse=", "),
               paste(names(ab), collapse=", ")))
}

# 3) Helper: Cohen's d (Hedges g correction)
cohens_d <- function(x, g){
  g <- droplevels(as.factor(g))
  if (nlevels(g) != 2) stop("cohens_d needs exactly two groups.")
  x1 <- x[g == levels(g)[1]]; x2 <- x[g == levels(g)[2]]
  m1 <- mean(x1); m2 <- mean(x2)
  s1 <- var(x1);  s2 <- var(x2)
  n1 <- length(x1); n2 <- length(x2)
  sp <- sqrt(((n1-1)*s1 + (n2-1)*s2) / (n1 + n2 - 2))
  d  <- (m1 - m2) / sp
  J  <- 1 - (3/(4*(n1+n2) - 9))
  d*J
}

# 4) Run Welch t-tests for the three pairs
pairs <- list(c("M","F"), c("M","I"), c("F","I"))

tt_rows <- lapply(pairs, function(p){
  subdat <- subset(ab, sex %in% p)
  subdat$sex <- droplevels(as.factor(subdat$sex))
  # Ensure order of levels matches pair order (so 'group1' and 'group2' are correct)
  subdat$sex <- factor(subdat$sex, levels = p)
  tt <- t.test(rings ~ sex, data = subdat)
  d  <- cohens_d(subdat$rings, subdat$sex)
  m1 <- mean(subdat$rings[subdat$sex == p[1]])
  m2 <- mean(subdat$rings[subdat$sex == p[2]])
  data.frame(
    group1 = p[1],
    group2 = p[2],
    mean1  = m1,
    mean2  = m2,
    diff   = m2 - m1,
    t      = unname(tt$statistic),
    df     = unname(tt$parameter),
    pval   = tt$p.value,
    ci_lo  = tt$conf.int[1],
    ci_hi  = tt$conf.int[2],
    cohens_d = d,
    sig_0_05 = ifelse(tt$p.value < 0.05, "Yes", "No"),
    direction = ifelse(m2 > m1, paste(p[2],">",p[1]), paste(p[1],">",p[2]))
  )
})

ttab <- do.call(rbind, tt_rows)
ttab

```

```{r}
apply(ttab, 1, function(row){
  paste0(
    "Comparing ", row["group1"], " vs ", row["group2"], ": mean rings = ",
    sprintf("%.2f", as.numeric(row["mean1"])), " vs ",
    sprintf("%.2f", as.numeric(row["mean2"])),
    " (difference ", sprintf("%.2f", as.numeric(row["diff"])), "). ",
    "Welch t(", sprintf("%.1f", as.numeric(row["df"])), ") = ",
    sprintf("%.2f", as.numeric(row["t"])), ", p = ",
    format(as.numeric(row["pval"]), digits = 3),
    ". 95% CI [", sprintf("%.2f", as.numeric(row["ci_lo"])), ", ",
    sprintf("%.2f", as.numeric(row["ci_hi"])), "]. ",
    "Cohen's d = ", sprintf("%.2f", as.numeric(row["cohens_d"])), ". ",
    if (row["sig_0_05"] == "Yes")
      paste0("There is evidence of a difference (", row["direction"], ").")
    else
      "No statistically significant difference at α = 0.05."
  )
})
```

```{r}
sexes  <- unique(abalone$sex)
pairs  <- combn(sexes, 2, simplify = FALSE)
lapply(pairs, function(p) {
  g1 <- abalone$rings[abalone$sex == p[1]]
  g2 <- abalone$rings[abalone$sex == p[2]]
  list(pair = paste(p, collapse = " vs "), ttest = t.test(g1, g2))
})
```

**Interpretation of t-tests:**\

The t-tests show differences in mean ring counts:

Male vs. Female: different mean rings (p \< 0.05). Females have slightly higher counts

Male vs. Infant: infants showing higher mean rings on average

Female vs. Infant: infants have the largest counts. The results show that age is not evenly distributed across sexes. The differences are large enough to be statistically meaningful.

# Problem 2

```{r}
# Guess a column name by matching patterns (case-insensitive).
guess_col <- function(nms, patterns) {
  for (p in patterns) {
    hits <- grep(p, nms, ignore.case = TRUE, value = TRUE)
    if (length(hits) > 0) return(hits[1])  # return first match
  }
  NA_character_
}
```

```{r}
food <- read.csv(food_path, stringsAsFactors = FALSE)
names(food) <- clean_names_base(names(food))
head(food, 3)

```

## Restrict to USD (show counts before/after)

```{r}
n_before <- nrow(food)
currency_col <- guess_col(names(food), c("^currency$","currency"))
food_usd <- food
if (!is.na(currency_col)) {
  cur_upper <- toupper(as.character(food[[currency_col]]))
  food_usd <- food[cur_upper == "USD", ]
}
data.frame(before = n_before, after_usd = nrow(food_usd))

```

```{r}
data.frame(
  step = c("USD subset start", "Age 18–100", "Valid state", 
           "Spend caps", "Dining-out 0–35 (integer)"),
  kept = c(n_after_currency, n1_after, n2_after, n3_after, n4_after)
)

```

## Cleaning rules (documented) and implementation

```{r}
# ------------------------------
# Problem 2 — Food Expenditure (using your exact headers)
# ------------------------------
suppressPackageStartupMessages(library(dplyr))

# 1) Import ---------------------------------------------------------------
food_raw <- read.csv("food_expenditure.csv", na.strings = c("", "NA"))
n0 <- nrow(food_raw)

# 2) Rename to simple, readable names ------------------------------------
food <- food_raw %>%
  rename(
    id                = ID,
    age               = What.is.your.age.,
    hh_nonself        = How.many.individuals.live.in.your.household.for.which.you.are.responsible.for.food.expenditures..excluding.yourself..,
    state             = What.state.do.you.live.in.,
    currency          = What.currency.are.you.reporting.your.food.expenditures.in.,
    total             = What.was.your.total.food.expenditure.in.the.last.week.,
    grocery           = What.was.your.total.food.expenditures.at.grocery.stores.in.the.last.week.,
    dining_out_spend  = What.was.your.food.expenditure.while.dining.out.in.the.last.week.,
    misc              = What.was.your.food.expenditure..miscellaneous..in.the.last.week.,
    dining_out_times  = How.many.times.did.you.dine.out.last.week.,
    include_alcohol   = Are.you.including.alcohol.in.your.food.expenditures.,
    assistance        = What.food.assistance.programs..if.any..did.you.use.for.your.food.expenditures.last.week.
  )

# 3) Restrict to USD & show counts ---------------------------------------
n_before_currency <- nrow(food)
food <- food %>% filter(!is.na(currency), toupper(currency) == "USD")
n_after_currency  <- nrow(food)
cat("Rows before currency filter:", n_before_currency, "\n")
cat("Rows after currency == 'USD':", n_after_currency, "\n\n")

# 4) Cleaning rules (documented) ------------------------------------------
# AGE: keep adults 18–100 inclusive (numeric, non-missing)
# STATE: keep valid US 50 states + DC + PR (two-letter codes)
# FOOD EXPENDITURES: numeric; non-negative; weekly caps: total ≤ 2000; others ≤ 1000
# DINING-OUT COUNT: integer-like, 0–35 inclusive

as_num <- function(x) suppressWarnings(as.numeric(x))

valid_states <- c(
  "AL","AK","AZ","AR","CA","CO","CT","DE","FL","GA",
  "HI","ID","IL","IN","IA","KS","KY","LA","ME","MD",
  "MA","MI","MN","MS","MO","MT","NE","NV","NH","NJ",
  "NM","NY","NC","ND","OH","OK","OR","PA","RI","SC",
  "SD","TN","TX","UT","VT","VA","WA","WV","WI","WY",
  "DC","PR"
)

# Coerce numerics
food <- food %>%
  mutate(
    age              = as_num(age),
    total            = as_num(total),
    grocery          = as_num(grocery),
    dining_out_spend = as_num(dining_out_spend),
    misc             = as_num(misc),
    dining_out_times = as_num(dining_out_times)
  )

# AGE filter
n1_before <- nrow(food)
food <- food %>% filter(!is.na(age), age >= 18, age <= 100)
n1_after  <- nrow(food)

# STATE filter (two-letter, valid set)
n2_before <- nrow(food)
food <- food %>%
  mutate(state = toupper(trimws(state))) %>%
  filter(!is.na(state), grepl("^[A-Z]{2}$", state), state %in% valid_states)
n2_after  <- nrow(food)

# EXPENDITURE filters
n3_before <- nrow(food)
food <- food %>%
  filter(
    !is.na(total)            & total            >= 0 & total            <= 2000,
    !is.na(grocery)          & grocery          >= 0 & grocery          <= 1000,
    !is.na(dining_out_spend) & dining_out_spend >= 0 & dining_out_spend <= 1000,
    !is.na(misc)             & misc             >= 0 & misc             <= 1000
  )
n3_after <- nrow(food)

# DINING-OUT COUNT filter
n4_before <- nrow(food)
food <- food %>%
  filter(!is.na(dining_out_times),
         dining_out_times >= 0,
         dining_out_times <= 35) %>%
  filter(abs(dining_out_times - round(dining_out_times)) < 1e-8) %>%
  mutate(dining_out_times = as.integer(round(dining_out_times)))
n4_after <- nrow(food)

# 5) Report counts & final N ----------------------------------------------
cat("After AGE filter (18–100):               ", n1_after, "of", n1_before, "\n")
cat("After STATE filter (valid 50 + DC + PR): ", n2_after, "of", n2_before, "\n")
cat("After EXPENDITURE caps (weekly reason.): ", n3_after, "of", n3_before, "\n")
cat("After DINING-OUT TIMES (0–35, integer):  ", n4_after, "of", n4_before, "\n\n")
cat("FINAL NUMBER OF OBSERVATIONS AFTER CLEANING:", nrow(food), "\n\n")

# Quick sanity summary (for the variables we cleaned)
summary(food[, c("age","state","total","grocery","dining_out_spend","misc","dining_out_times")])


```

After restricting to respondents reporting in USD, four cleaning steps are applied:

Minors and implausible ages are excluded by keeping only respondents aged 18–100.

The state variable is limited to valid two-letter postal codes (50 states plus DC and PR).

Entries with negative or extreme weekly food expenditures are removed: total ≤ \$2000, and grocery/dining/miscellaneous components each ≤ \$1000.

Dining-out counts are required to be integers between 0 and 35 to remove outliers and non-integer values.

The final dataset totals 130.

# Problem 3 — Collatz Conjecture

```{r}
nextCollatz <- function(n) {
  if (length(n)!=1 || !is.numeric(n) || n<=0 || n!=as.integer(n)) stop("positive integer required")
  if (n %% 2 == 0) n/2 else 3*n+1
}

collatzSequence <- function(n) {
  if (length(n)!=1 || !is.numeric(n) || n<=0 || n!=as.integer(n)) stop("positive integer required")
  seq <- n
  while (n != 1) {
    n <- nextCollatz(n)
    seq <- c(seq, n)
  }
  list(sequence = seq, length = length(seq))
}

# Examples
nextCollatz(5)
nextCollatz(16)
collatzSequence(5)$sequence
collatzSequence(19)$sequence

```

## Shortest and longest Collatz sequences for starts 100–500 (ties → smallest start)

```{# --- Problem 3 — Collatz Conjecture (corrected & documented) ---}

#' Next step in the Collatz sequence
#'
#' @param n Positive integer (length 1)
#' @return Next positive integer in the Collatz sequence
#' @examples
#' nextCollatz(5)   # 16
#' nextCollatz(16)  # 8
nextCollatz <- function(n) {
  if (length(n) != 1 || !is.numeric(n) || is.na(n) ||
      n <= 0 || n != as.integer(n)) {
    stop("Input must be a positive integer (length 1).")
  }
  if (n %% 2 == 0) n / 2 else 3L * n + 1L
}

#' Generate the Collatz sequence until it reaches 1
#'
#' @param n Positive integer (length 1)
#' @return A list with:
#' \item{sequence}{Integer vector from n down to 1 following Collatz rules}
#' \item{length}{Integer length of that sequence}
#' @examples
#' collatzSequence(5)$sequence   # 5 16 8 4 2 1
#' collatzSequence(19)$length    # e.g., 21
collatzSequence <- function(n) {
  if (length(n) != 1 || !is.numeric(n) || is.na(n) ||
      n <= 0 || n != as.integer(n)) {
    stop("Input must be a positive integer (length 1).")
  }
  seq <- as.integer(n)
  while (n != 1L) {
    n <- nextCollatz(n)
    seq <- c(seq, as.integer(n))
  }
  list(sequence = seq, length = length(seq))
}

# ---- Demonstrations (must reproduce prompt examples) ----
nextCollatz(5)    # should be 16
nextCollatz(16)   # should be 8

collatzSequence(5)$sequence
collatzSequence(19)$sequence

# ---- Search starts 100..500 for shortest/longest sequences ----
starts <- 100:500
results <- lapply(starts, function(s) {
  info <- collatzSequence(s)
  list(start = s, length = info$length)
})
lens <- sapply(results, function(r) r$length)

# Tie-breaking: choose the *lowest* start among ties
shortest_len   <- min(lens)
shortest_start <- min(starts[lens == shortest_len])

longest_len    <- max(lens)
longest_start  <- min(starts[lens == longest_len])

# Present results clearly
out <- data.frame(
  metric = c("shortest", "longest"),
  start  = c(shortest_start, longest_start),
  length = c(shortest_len,  longest_len)
)
out

# (Optional) show the actual longest sequence
# collatzSequence(longest_start)$sequence

```

```{r}
# --- Problem 3: Shortest and longest Collatz sequences (100–500) ---

# Generate lengths for each starting value
results <- lapply(100:500, function(x) {
  seq_info <- collatzSequence(x)
  list(start = x, length = seq_info$length)
})

# Extract sequence lengths
lens <- sapply(results, function(r) r$length)

# Identify shortest and longest
shortest_start <- results[[which.min(lens)]]$start
shortest_len   <- min(lens)

longest_start  <- results[[which.max(lens)]]$start
longest_len    <- max(lens)

# Report nicely
cat("Shortest sequence between 100–500 starts at", shortest_start,
    "with length", shortest_len, "\n")
cat("Longest sequence between 100–500 starts at", longest_start,
    "with length", longest_len, "\n")

```

The Collatz sequence functions worked.

When searching starting values between 100 and 500, the shortest sequence originated at **100**, reaching 1 in relatively few steps. The longest sequence originated at **371**, taking over 140 steps to reach 1. These results illustrate the conjecture’s unpredictable behavior: nearby starting values can yield very different path lengths, even though all eventually converge to 1.
